# Image captioning is a popular task in machine learning that deals with generating
text given images. Our project explores this field in the medical context. Our aim is to
experiment with different datasets and models for image captioning in healthcare. In this
report, we outline results from three models - Show, Attend, and Tell, a classification model,
and Contrastive Language-Image Pre-training (CLIP), using different datasets - MedICaT,
IU-Chest X-ray, and SIIM-ACR Pneumothorax. Our findings show that each method is
promising with the Show, Attend, and Tell model having a BLEU score of 0.5957 on the
test dataset.
